{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOaxLsvi8y0Ee3hxn0AewkN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gforconi/UTNIA2025/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "tW9D-RFVUJMi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduccion a Pytorch\n",
        "\n",
        "Pytorch es una libreria que permite trabajar con vectores y matrices de muchas dimensiones.\n",
        "\n",
        "En ese sentido es muy parecido a Numpy. En numpy a los vectores son llamados arrays. En pytorch se los llama tensores."
      ],
      "metadata": {
        "id": "aym_yfMPUE70"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1bPHectQTVUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1635cc6-5f03-41f3-8a84-ccbed078bba2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3.,  6.],\n",
              "        [ 9., 12.],\n",
              "        [ 1.,  2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "a = torch.tensor([[3.,6.],[9.,12.], [1.,2.]])\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BoN4tYvUZS8",
        "outputId": "4d76612a-42d9-45f9-9016-0fa9a7f77f64"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El shape del tensor es una lista del tamano de cada dimension. Si trabajamos con matrices (como comumnmente se llama a los vectores 2D), cada \"fila\" tiene la misma longitud: no hay una fila mas corta que otra.\n",
        "\n",
        "Lo mismo vale para mas dimensiones. No podemos hacer:"
      ],
      "metadata": {
        "id": "LlF7_o5JUemX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([[1., 2.], [3., 4.]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "CmcWDnDxUd4Y",
        "outputId": "a74969c1-a18e-48cb-a96a-54c2ac4aa298"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "expected sequence of length 2 at dim 1 (got 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-50bc8b394db2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: expected sequence of length 2 at dim 1 (got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El `ValueError` se debe a que las longitudes de las filas `[1., 2.]` y `[3]` no coinciden."
      ],
      "metadata": {
        "id": "I-brPNgUkOnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensores con Pytorch\n",
        "\n",
        "Un tensor es un concepto matem치tico que generaliza escalares, vectores y matrices hacia dimensiones superiores. Para ilustrarlo, un tensor de orden 0 se reduce a un escalar, mientras que un tensor de orden 1 se convierte en un vector. Cuando llegamos a una matriz de dos dimensiones, estamos ante un tensor de orden 2, y as칤 sucesivamente hasta llegar a n dimensiones. Los tensores tienen una amplia aplicaci칩n en distintos 치mbitos, desde las matem치ticas y la f칤sica hasta la inform치tica y el aprendizaje autom치tico.\n",
        "\n",
        "En el contexto del aprendizaje autom치tico y el aprendizaje profundo, los tensores son la base de datos fundamental que representa las entradas, salidas y el estado interno de una red neuronal.\n",
        "\n",
        "PyTorch, en su esencia, es una biblioteca especializada en el procesamiento de tensores. Ofrece una amplia variedad de funciones altamente optimizadas para operar eficientemente con estos objetos, incluyendo operaciones cruciales como multiplicaciones de matrices y convoluciones. Adem치s, PyTorch se integra sin problemas con aceleradores de hardware como las GPU, lo que puede impulsar de manera significativa los c치lculos necesarios en el aprendizaje profundo. Esta capacidad de PyTorch para trabajar con tensores y aprovechar al m치ximo el hardware subyacente lo convierte en una herramienta fundamental en el campo del aprendizaje autom치tico y la inteligencia artificial."
      ],
      "metadata": {
        "id": "PjNGojrXiPTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creaci칩n de tensores\n",
        "\n",
        "A continuaci칩n varios ejemplos de c칩mo crear tensores en con Pytorch.\n"
      ],
      "metadata": {
        "id": "upA5fP3kixzT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Escalares**"
      ],
      "metadata": {
        "id": "oySL--O1i1Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escalares en PyTorch (tensor de orden 0)\n",
        "t1 = torch.tensor(4.)\n",
        "print(t1)\n",
        "print(\"Orden del tensor:\", t1.dim())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvR4lzlJiWOP",
        "outputId": "15b468a0-eb1a-4444-9eff-de3c51ce1c04"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n",
            "Orden del tensor: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`4.` es una abreviatura de `4.0.` Se emplea para indicar a Python (y PyTorch) que se desea crear un n칰mero en formato de coma flotante (`float`). Esto se puede verificar al revisar el atributo `dtype` de nuestro tensor."
      ],
      "metadata": {
        "id": "E7kW_enPi-n2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tipo de dato de un tensor\n",
        "t1.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEN0nKHNjIIT",
        "outputId": "a9be5f99-8f7e-4c3b-a416-7a26fdbaca4c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Vectores**"
      ],
      "metadata": {
        "id": "bO0YykB3jLXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector de 1 dimensi칩n (tensor de orden 1)\n",
        "t2 = torch.tensor([1, 2, 3, 4])\n",
        "print(t2)\n",
        "print(f\"Orden del tensor: {t2.ndim}\")\n",
        "print(f\"Forma del tensor: {t2.shape}\")\n",
        "print(f\"Tipo de dato del tensor: {t2.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfs0T-WDjLMP",
        "outputId": "12e76b0b-d277-43bd-8356-ce60cdd60805"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4])\n",
            "Orden del tensor: 1\n",
            "Forma del tensor: torch.Size([4])\n",
            "Tipo de dato del tensor: torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todos los elementos de un tensor tienen el mismo tipo. Por esta raz칩n, al crear un tensor que combina valores `float` y valores `int`, el tensor resultante adquiere el tipo `float`."
      ],
      "metadata": {
        "id": "K6dtecFljRra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2_mix = torch.tensor([1.0, 2, 3, 4])\n",
        "print(t2_mix)\n",
        "print(f\"Orden del tensor: {t2_mix.ndim}\")\n",
        "print(f\"Forma del tensor: {t2_mix.shape}\")\n",
        "print(f\"Tipo de dato del tensor: {t2_mix.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k30DCRCqjXTE",
        "outputId": "190c17a5-6614-4175-b76f-819a218a31fc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4.])\n",
            "Orden del tensor: 1\n",
            "Forma del tensor: torch.Size([4])\n",
            "Tipo de dato del tensor: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Matrices**"
      ],
      "metadata": {
        "id": "YhXrl-8cjaND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrices\n",
        "t3 = torch.tensor([[5., 6],\n",
        "                   [7, 8],\n",
        "                   [9, 10]])\n",
        "print(t3)\n",
        "print(f\"Orden del tensor: {t3.ndim}\")\n",
        "print(f\"Forma del tensor: {t3.shape}\")\n",
        "print(f\"Tipo de dato del tensor: {t3.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZIu_s6hjzgR",
        "outputId": "dc054e7b-bde6-4c57-d431-a0021dfb16c5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5.,  6.],\n",
            "        [ 7.,  8.],\n",
            "        [ 9., 10.]])\n",
            "Orden del tensor: 2\n",
            "Forma del tensor: torch.Size([3, 2])\n",
            "Tipo de dato del tensor: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tensor de 3 dimensiones**\n",
        "\n"
      ],
      "metadata": {
        "id": "mS3vWxL1j39c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor tridimensional\n",
        "t4 = torch.tensor([\n",
        "    [[11, 12, 13, 10],\n",
        "     [11, 12, 13, 10],\n",
        "     [13, 14, 15, 10]],\n",
        "    [[15, 16, 17, 10],\n",
        "     [11, 12, 13, 10],\n",
        "     [17, 18, 19., 10]]])"
      ],
      "metadata": {
        "id": "u4kg37Uyj6Qh"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tensor de orden  洧녵**\n",
        "\n",
        "Los tensores pueden tener cualquier n칰mero de dimensiones y diferentes longitudes a lo largo de cada dimensi칩n. Se puede inspeccionar la longitud a lo largo de cada dimensi칩n usando el atributo `.shape`. Al igual que pasa con NumPy, no es posible crear tensores con una dimensionalidad incompatible."
      ],
      "metadata": {
        "id": "eX0kIBxskAdI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generaci칩n de Tensores Aleatorios\n",
        "\n",
        "En el contexto de los modelos de aprendizaje autom치tico, como las redes neuronales, se manipulan y buscan patrones dentro de los tensores. Por lo general, un modelo de aprendizaje autom치tico comienza con tensores de n칰meros aleatorios (pesos y bias) que posteriormente se ajustan a medida que procesa los datos de entrenamiento y aprende de ellos.\n",
        "\n",
        "Para crear tensores con n칰meros aleatorios entre [0,1] se utiliza la funic칩n `torch.rand()` pasando el par치metro `size`."
      ],
      "metadata": {
        "id": "bX_rMDZ4knkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor con valores aleatorios de dimensiones (3, 4)\n",
        "tensor_aleatorio = torch.rand(size=(3, 4))\n",
        "print(tensor_aleatorio)\n",
        "print(f\"Orden del tensor: {tensor_aleatorio.ndim}\")\n",
        "print(f\"Forma del tensor: {tensor_aleatorio.shape}\")\n",
        "print(f\"Tipo de dato del tensor: {tensor_aleatorio.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOHPuzsdkl1g",
        "outputId": "7fcb68c2-2f40-40c4-baba-42bc0cbb9ff0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6546, 0.8298, 0.5365, 0.5581],\n",
            "        [0.6686, 0.4676, 0.7414, 0.3003],\n",
            "        [0.2640, 0.9841, 0.5748, 0.3204]])\n",
            "Orden del tensor: 2\n",
            "Forma del tensor: torch.Size([3, 4])\n",
            "Tipo de dato del tensor: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Operaciones con tensores\n",
        "\n",
        "Para poder crear, entrenar y luego realizar predicciones con una red neuronal, es esencial llevar a cabo operaciones fundamentales entre tensores, que incluyen:\n",
        "\n",
        "*   Suma\n",
        "*   Resta\n",
        "*   Multiplicaci칩n (elemento a elemento)\n",
        "*   Divisi칩n\n",
        "*   Multiplicaci칩n de matrices"
      ],
      "metadata": {
        "id": "DqNJ-jCbk-fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Suma\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZdR3x8elIoJ",
        "outputId": "f7c697f1-a631-4821-9a29-ec9712ce4d62"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resta\n",
        "tensor = tensor - 10\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbFGY51mlOyj",
        "outputId": "1c47681a-8708-4e05-8a23-cb400c25ffb4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplicaci칩n por un escalar\n",
        "tensor * 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RydqtQ_4lLTT",
        "outputId": "06c1c068-fe14-40b9-f037-2b24f60e23b0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-90, -80, -70])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiplicaci칩n de matrices\n",
        "\n",
        "\n",
        "La [multiplicaci칩n de matrices](https://www.mathsisfun.com/algebra/matrix-multiplying.html) es una de las operaciones m치s comunes en algoritmos de aprendizaje autom치tico y aprendizaje profundo, como las redes neuronales. En PyTorch, esta funcionalidad se implementa a trav칠s del m칠todo torch.matmul(). Hay dos reglas principales a tener en cuenta al multiplicar matrices:\n",
        "\n",
        "\n",
        "\n",
        "1.   Las **dimensiones internas** deben coincidir:\n",
        "\n",
        "\n",
        "\n",
        "*   `(3, 2) @ (3, 2)` no es v치lido\n",
        "*   `(2, 3) @ (3, 2)` es v치lido\n",
        "*   `(3, 2) @ (2, 3)` es v치lido\n",
        "\n",
        "\n",
        "2.   La matriz resultante tiene la forma de las **dimensiones externas**:\n",
        "*   `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
        "*   `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
        "\n"
      ],
      "metadata": {
        "id": "V5WY0Nn3lX8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es importante diferenciar entre la multiplicaci칩n elemento a elemento (element wise) y la multiplicaci칩n de matrices. Por ejemplo, para un `tensor` con valores `[1, 2, 3]`:\n",
        "\n",
        "| **Operaci칩n**                       | **C치lculo**                                | **C칩digo**                |\n",
        "|------------------------------------|--------------------------------------------|---------------------------|\n",
        "| Multiplicaci칩n elemento a elemento | `[1*1, 2*2, 3*3] = [1, 4, 9]`               | `tensor * tensor`         |\n",
        "| Multiplicaci칩n de matrices         | `[1*1 + 2*2 + 3*3] = [14]`                  | `tensor.matmul(tensor)`   |\n"
      ],
      "metadata": {
        "id": "a0_zydYwmb-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3])"
      ],
      "metadata": {
        "id": "pbNQRj70m9l9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplicaci칩n elemento a elemento de tensores\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor * tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmjA2pBom-Ui",
        "outputId": "bcf4d452-d1e5-4e51-bf42-c0f833e27b9c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplicaci칩n matricial con el operador @\n",
        "tensor @ tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4ltH3EmnCP8",
        "outputId": "5cdba2f5-2516-40a8-c47f-5ee90c7c6383"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplicaci칩n matricial con el m칠todo matmul\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bGVQYEnnLgK",
        "outputId": "20912dda-0109-4b50-9b49-3925c334dde0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C치lculo del valor m치ximo, m칤nimo, m칠dia y suma de un tensor"
      ],
      "metadata": {
        "id": "NRcBt0nSnRaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# C치lculo del valor m치ximo, m칤nimo, m칠dia y suma de un tensor\n",
        "x = torch.tensor([1,2,1,3,1,2], dtype=torch.float32)  # para calcular la media hay que convertir a float\n",
        "print(f\"Min: {x.min()}\")\n",
        "print(f\"Max: {x.max()}\")\n",
        "print(f\"Media: {x.mean()}\")\n",
        "print(f\"Suma: {x.sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-yZV6QAnTo2",
        "outputId": "2e33244a-d225-484d-d239-d20a63389111"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min: 1.0\n",
            "Max: 3.0\n",
            "Media: 1.6666666269302368\n",
            "Suma: 10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 칈ndices de los Valores M치ximo y M칤nimo\n",
        "\n",
        "Es posible determinar el 칤ndice de un tensor donde se encuentra el valor m치ximo o m칤nimo utilizando las funciones `torch.argmax()` y `torch.argmin()`. Esta operaci칩n resulta 칰til en situaciones en las que s칩lo se requiere conocer la posici칩n del valor m치s alto (o m치s bajo), y no el valor en s칤. Veremos un ejemplo de esto m치s adelante cuando utilicemos la funci칩n de activaci칩n softmax."
      ],
      "metadata": {
        "id": "EWK2R-EVnYH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenci칩n del 칤ndice del valor m치ximo y m칤nimo de un tensor\n",
        "tensor = torch.arange(10, 100, 10)\n",
        "print(f\"Tensor: {tensor}\")\n",
        "\n",
        "# Se devuelve el 칤ndice del valor m치ximo y m칤nimo\n",
        "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
        "print(f\"Index where min value occurs: {tensor.argmin()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoS-lN6OniAk",
        "outputId": "bed0a75f-ab49-47f8-c0ab-fe582b7fc2c7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "Index where max value occurs: 8\n",
            "Index where min value occurs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Que introduce de nuevo pytorch sobre numpy\n",
        "Esencialmente dos cosas:\n",
        "\n",
        "*   Paralelizacion en GPU\n",
        "*   Calculo automatico de derivadas (gradiente)\n",
        "\n",
        "\n",
        "Estas funciones son muy deseables cuando trabajamos con redes neuronales. Aunque tambien hay librerias de, por ejemplo, algebra lineal que han aprovechado esto para ser escritas sobre pytorch y funcionar eficientemente.\n",
        "\n",
        "Pytorch tambien provee muchas de las funcionalidades necesarias para definir una red y entrenarla.\n",
        "\n",
        "Con la siguiente funcion podemos ver si tenemos una GPU disponible en nuestro sistema"
      ],
      "metadata": {
        "id": "-jtWib7iUs2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEgDIhzrU7Ec",
        "outputId": "4cc8b59f-fded-49b2-8849-60f0bcd2b228"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos comparar la velocidad entre ejecutar algo en CPU o usando GPU (si tenemos).\n",
        "\n",
        "Pytorch requiere mover explicitamente los tensores a la GPU, se puede hacer facilmente mediante el metodo .cuda()\n",
        "\n",
        "(Si se operan vectores que estan en la GPU con vectores que estan en la GPU causara un error)"
      ],
      "metadata": {
        "id": "J3R1PzDRU-_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.rand(1000,1000)\n",
        "B = torch.rand(1000,1000)"
      ],
      "metadata": {
        "id": "t5pLuG51VDc1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit A@B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znmJKPf3VFQo",
        "outputId": "f4a8a2a5-67bc-4f0d-ba0b-2152d85a65ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32.8 ms 췀 3.05 ms per loop (mean 췀 std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.rand(1000,1000)\n",
        "B = torch.rand(1000,1000)\n",
        "if torch.cuda.is_available():\n",
        "    A = A.cuda()\n",
        "    B = B.cuda()\n",
        "    print(\"CUDA available\")\n",
        "else:\n",
        "    print(\"CUDA not available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8t6P_C9VJRD",
        "outputId": "45aed761-5de3-495d-acd8-85095bac336b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit A@B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTKSs_xmVcv6",
        "outputId": "3825c436-9fe6-4a38-877d-72920e35c3f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "556 췃s 췀 17.5 췃s per loop (mean 췀 std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si ten칠s iOS (Mac) pod칠s ver como acelerar Pytorch con el backedn MPS (solo disponible para AMD o Sillicon Chip, NO Intel)."
      ],
      "metadata": {
        "id": "J2kVhf7RVk13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.backends.mps.is_available():\n",
        "    mps_device = torch.device(\"mps\")\n",
        "    print(\"MPS available\")\n",
        "    A = A.to(mps_device)\n",
        "    B = B.to(mps_device)\n",
        "else:\n",
        "    print (\"MPS device not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AmS8iM-VkM8",
        "outputId": "c76de7f4-3ec8-4752-dcde-b2b1e24ae0ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MPS device not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit A@B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuJ1oyDvVsqd",
        "outputId": "0045e3e2-ec99-4bf5-95dc-8d4f9fa66ffe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "575 췃s 췀 15.6 췃s per loop (mean 췀 std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd\n",
        "\n",
        "Autograd es una biblioteca de PyTorch que implementa la diferenciaci칩n autom치tica. Utiliza la estructura gr치fica para calcular gradientes y permite que el modelo aprenda actualizando sus par치metros durante el entrenamiento. Autograd tambi칠n permite calcular gradientes con respecto a valores escalares arbitrarios, lo cual resulta 칰til para tareas como la optimizaci칩n.\n",
        "\n",
        "Es necesaria la instalacion de complementos en el sistema operativo y de la libreria `torchviz`"
      ],
      "metadata": {
        "id": "yCufW9M0cXrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y graphviz\n",
        "!pip install torchviz"
      ],
      "metadata": {
        "id": "fD_vlsVLXXzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchviz import make_dot\n",
        "\n",
        "# Creamos un tensor y asignamos el valor 7\n",
        "# seteamos requires_grad=True\n",
        "# Entonces, autograd registrar치 las operaciones\n",
        "x=torch.tensor(7.0,requires_grad=True)\n",
        "\n",
        "# Definimos la funcion\n",
        "f = (x**2)+3\n",
        "\n",
        "# Diferencial usando torch\n",
        "# Utiliza la funcion inversa para calcualr el valor del gradiente\n",
        "f.backward()\n",
        "\n",
        "# Imprimimos el valor de la derivada de \"y\"\n",
        "# es decir, dy/dx = 2x  = 2 X 7.0 = 14.\n",
        "print(x.grad)\n",
        "\n",
        "# Imprimimos el grafo computacional\n",
        "make_dot(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "1yrWTSyVYXgC",
        "outputId": "afa8ef6e-add6-48ff-862d-954636ba5b32"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(14.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"109pt\" height=\"271pt\"\n viewBox=\"0.00 0.00 109.00 271.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 267)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-267 105,-267 105,4 -4,4\"/>\n<!-- 137462710737360 -->\n<g id=\"node1\" class=\"node\">\n<title>137462710737360</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 137463050253936 -->\n<g id=\"node2\" class=\"node\">\n<title>137463050253936</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-86 6,-86 6,-67 95,-67 95,-86\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 137463050253936&#45;&gt;137462710737360 -->\n<g id=\"edge4\" class=\"edge\">\n<title>137463050253936&#45;&gt;137462710737360</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n</g>\n<!-- 137463050244864 -->\n<g id=\"node3\" class=\"node\">\n<title>137463050244864</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 137463050244864&#45;&gt;137463050253936 -->\n<g id=\"edge1\" class=\"edge\">\n<title>137463050244864&#45;&gt;137463050253936</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.75C50.5,-114.8 50.5,-104.85 50.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-96.09 50.5,-86.09 47,-96.09 54,-96.09\"/>\n</g>\n<!-- 137463050254320 -->\n<g id=\"node4\" class=\"node\">\n<title>137463050254320</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-196 0,-196 0,-177 101,-177 101,-196\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 137463050254320&#45;&gt;137463050244864 -->\n<g id=\"edge2\" class=\"edge\">\n<title>137463050254320&#45;&gt;137463050244864</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.75C50.5,-169.8 50.5,-159.85 50.5,-151.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.09 50.5,-141.09 47,-151.09 54,-151.09\"/>\n</g>\n<!-- 137463078805264 -->\n<g id=\"node5\" class=\"node\">\n<title>137463078805264</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-263 23.5,-263 23.5,-232 77.5,-232 77.5,-263\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 137463078805264&#45;&gt;137463050254320 -->\n<g id=\"edge3\" class=\"edge\">\n<title>137463078805264&#45;&gt;137463050254320</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.92C50.5,-224.22 50.5,-214.69 50.5,-206.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-206.25 50.5,-196.25 47,-206.25 54,-206.25\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7d05a4589810>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd a otro nivel\n",
        "\n",
        "Podemos definir vectores con ciertos valores y crear otros como resultado de operar los primeros y pytorch recordara el grafo de las computaciones.\n",
        "\n",
        "Supongamos que tenemos los valores:\n",
        "\n",
        "$ a = 1 $\n",
        "\n",
        "$ b = 2 $\n",
        "\n",
        "$ c = 0 $\n",
        "\n",
        "Y definimos $m$, $n$ (capas intermedias), $p$ (una prediccion) y $l$ (un costo) como:\n",
        "\n",
        "$ m = a + b $\n",
        "\n",
        "$ n = max(b,c) $\n",
        "\n",
        "$ p = m \\times n $\n",
        "\n",
        "$ l = p^2 $\n",
        "\n",
        "Pytorch calculara los valores intermedios dado el valor de las hojas:\n",
        "\n",
        "$ m = 3 $\n",
        "\n",
        "$ n = 2 $\n",
        "\n",
        "$ p = 6 $\n",
        "\n",
        "$ l = 36 $\n",
        "\n",
        "Y a la vez construira el siguiente grafo de computaciones (https://csacademy.com/app/graph_editor/)\n",
        "\n",
        "![Grafo](graph.png)\n",
        "\n",
        "Si $a$,$b$,$c$ son nuestros parametros y queremos minimizar el costo $l$. Querremos calcular: $\\Large\\frac{\\partial l}{\\partial a}$, $\\Large\\frac{\\partial l}{\\partial b}$, $\\Large\\frac{\\partial l}{\\partial c}$\n",
        "\n",
        "A primera vista no es f치cil calcular dichas derivadas. En general, usando la definici칩n de los valores, podemos calcular la derivada de un valor en funci칩n de los valores que dependen de forma directa de 칠l. Haciendo referencia al grafo de las computaciones (la imagen de arriba), podemos calcular el valor de $\\large\\frac{\\partial y}{\\partial x}$ si existe una arista que $x \\rightarrow y$. As칤, podemos calcular las siguientes derivadas, ya que cada variable depende de forma directa una de la otra:\n",
        "\n",
        "$\\large\\frac{\\partial l}{\\partial p} = 2 \\times p = 12$\n",
        "\n",
        "$\\large\\frac{\\partial p}{\\partial m} = n = 2$\n",
        "\n",
        "$\\large\\frac{\\partial p}{\\partial n} = m = 3$\n",
        "\n",
        "$\\large\\frac{\\partial m}{\\partial a} = 1$\n",
        "\n",
        "$\\large \\frac{\\partial m}{\\partial b} = 1$\n",
        "\n",
        "$\\large \\frac{\\partial n}{\\partial b} = 1$\n",
        "\n",
        "$\\large \\frac{\\partial n}{\\partial c} = 0$\n",
        "\n",
        "Pero como hacemos para calcular las derivadas $\\Large\\frac{\\partial l}{\\partial a}$, $\\Large\\frac{\\partial l}{\\partial b}$, $\\Large\\frac{\\partial l}{\\partial c}$ que son las que necesitamos para actualizar el gradiente?\n",
        "\n",
        "Centr칠mosnos por un momento en el caso de $\\Large\\frac{\\partial l}{\\partial a}$. Si bien no tenemos una f칩rmula que relacione de manera directa $a$ con $l$, el valor de $l$ depende del valor de $a$: esto es debido a que el valor de $l$ depende de $p$, que a su vez depende de $m$, que por 칰ltimo depende de $a$.\n",
        "\n",
        "Apliquemos la [regla de la cadena](https://en.wikipedia.org/wiki/Chain_rule) entre $p$ (que es una funci칩n de $a$), $l$ (que es funci칩n de $p$) y $a$:\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial a} = \\frac{\\partial l}{\\partial p} \\times \\frac{\\partial p}{\\partial a}$\n",
        "\n",
        "Mirando el t칠rmino de la derecha:\n",
        "- $\\Large \\frac{\\partial l}{\\partial p}$ lo conocemos y vale $12$.\n",
        "- $\\Large \\frac{\\partial p}{\\partial a}$ no lo hemos calculado a칰n, pero nos hemos \"acercado\" a $a$ en el grafo de las computaciones. Todo indica que si aplicamos una vez m치s la regla de la cadena terminaremos llegando a $a$. Apliquemos pues, la regla de la cadena sobre $m$, $p$ y $a$:\n",
        "\n",
        "$\\Large\\frac{\\partial p}{\\partial a} = \\frac{\\partial p}{\\partial m} \\times \\frac{\\partial m}{\\partial a}$\n",
        "\n",
        "Ahora, mirando el t칠rmino de la derecha, tenemos todos los valores: $\\Large \\frac{\\partial p}{\\partial m}$ vale 2 y $\\Large \\frac{\\partial m}{\\partial a}$ vale 1.\n",
        "\n",
        "Ya estamos en condiciones pues de calcular $\\Large\\frac{\\partial l}{\\partial a}$:\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial a} = \\frac{\\partial l}{\\partial p} \\times \\frac{\\partial p}{\\partial a} = 12 \\times \\frac{\\partial p}{\\partial m} \\times \\frac{\\partial m}{\\partial a} = 12 \\times 2 \\times 1 = 24$\n",
        "\n",
        "Ordenando nuestro razonamiento, lo que estamos haciendo es calcular los gradientes respecto de las variables que est치n m치s cerca del resultado:\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial m} = \\frac{\\partial l}{\\partial p} \\times \\frac{\\partial p}{\\partial m} = 12 \\times 2 = 24$\n",
        "\n",
        "\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial n} = \\frac{\\partial l}{\\partial p} \\times \\frac{\\partial p}{\\partial n} = 12 \\times 3 = 36$\n",
        "\n",
        "Y luego utilizar dichos gradientes para calcular los de las capas anteriores:\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial a} = \\frac{\\partial l}{\\partial m} \\times \\frac{\\partial m}{\\partial a} = 24 \\times 1 = 24$\n",
        "\n",
        "\n",
        "Podemos hacer lo mismo para calcular $\\Large\\frac{\\partial l}{\\partial c}$.\n",
        "\n",
        "\n",
        "Para el caso de $b$ usamos la [regla de la cadena multivariada](https://math.hmc.edu/calculus/hmc-mathematics-calculus-online-tutorials/multivariable-calculus/multi-variable-chain-rule/) (es muy parecida a la regla del producto, de hecho la regla del producto es un caso particular de la regla de la cadena multivariada). Esta aplica porque $b$ es usada en varios valores ($m$ y $n$) de los cuales depende en 칰ltima instancia el valor que queremos diferenciar $l$.\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial b} = \\frac{\\partial l}{\\partial m} \\times \\frac{\\partial m}{\\partial b} + \\frac{\\partial l}{\\partial n} \\times \\frac{\\partial n}{\\partial b} = 24+36 = 60$\n"
      ],
      "metadata": {
        "id": "k-OJkc4Hc1xU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a calcular los gradientes usando [Pytorch Autograd](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html) (diferenciaci칩n autom치tica).\n",
        "\n",
        "Primero definimos los valores hoja (de los que depende el resto). Ser칤an nuestro par치metros (respecto de los cuales vamos a derivar despu칠s). Es importante el argumento requires_grad para que Pytorch sepa que tiene que calcular el grafo de las computaciones que le apliquemos a dichas variables, porque vamos a querer el gradiente respecto a dichas variables:"
      ],
      "metadata": {
        "id": "i0wfTsC6dsyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1.],requires_grad=True)\n",
        "b = torch.tensor([2.],requires_grad=True)\n",
        "c = torch.tensor([0.],requires_grad=True)\n",
        "a,b,c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mczHZe7Ldv4o",
        "outputId": "96f53f22-870b-4521-e3de-0a6f47790aaa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.], requires_grad=True),\n",
              " tensor([2.], requires_grad=True),\n",
              " tensor([0.], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora podemos definir otros valores en relaci칩n a los anteriores. En grad_fn lo que vemos es que Pytorch est치 llevando un historial de como dichos valores fueron contru칤dos. Esto es el grafo de las computaciones que luego le servir치 para calcular el gradiente:"
      ],
      "metadata": {
        "id": "YiHGlJNad58k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = a+b\n",
        "n = torch.max(a,b)\n",
        "m, n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dl1lCdKd7vi",
        "outputId": "45c927a5-e650-41e8-b586-a49e9cbbe52c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([3.], grad_fn=<AddBackward0>),\n",
              " tensor([2.], grad_fn=<MaximumBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = m*n\n",
        "l = p**2\n",
        "p, l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VxG8GBwd9kE",
        "outputId": "3d8e93e8-045b-4269-f70c-c27ba91ef69f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([6.], grad_fn=<MulBackward0>), tensor([36.], grad_fn=<PowBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para calcular el gradiente de $l$ basta con llamar l.backwards()\n",
        "\n",
        "Generalmente s칩lo usamos los gradientes respecto a los par치metros (las hojas). Si bien Pytorch calcula los gradientes respecto a los nodos intermedios (es un resultado parcial que luego ayudar치 para calcular los gradientes en las hojas), los borra autom치ticamente luego de usarlos para ahorrar memoria. Esto se puede evitar con el m칠todo .retain_grad(). En este caso le pediremos a Pytorch que no los borre ya que los queremos mostrar para corroborar que nos dio el mismo resultado que el que hallamos de manera anal칤tica:"
      ],
      "metadata": {
        "id": "weK2QLGeeDf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m.retain_grad()\n",
        "n.retain_grad()\n",
        "p.retain_grad()\n",
        "l.retain_grad()\n",
        "\n",
        "l.backward()"
      ],
      "metadata": {
        "id": "2i1m0N0deHEX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por 칰ltimo mostramos los gradientes de $l$ respecto a cada una de las variables. Podemos corroborar que los valores son los mismo que los hallados de manera anal칤tica arriba:"
      ],
      "metadata": {
        "id": "jLunGkFfeLYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l.grad, p.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToB28OfAeKzx",
        "outputId": "f54d6a9b-0631-4bf7-ff94-e93157e4210f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.]), tensor([12.]))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.grad, n.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoNqf-E9eQTS",
        "outputId": "55ea56ab-f2e0-43ff-8d31-8d32d694a4e6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([24.]), tensor([36.]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad, b.grad, c.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJX8vUryeSpG",
        "outputId": "1e81b83c-ab24-4ca8-f535-86c3af8baf4c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([24.]), tensor([60.]), None)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretaci칩n del gradiente\n",
        "\n",
        "Recordar que el gradiente $\\Large \\frac{\\partial l}{\\partial a}$ indica cu치nto cambia $l$ ante peque침os cambios de $a$:\n",
        "\n",
        "$\\Large \\frac{\\partial l}{\\partial a} = lim_{\\Delta a \\rightarrow 0} \\frac{\\Delta l}{\\Delta a}$\n",
        "\n",
        "Corroboraremos esto emp칤ricamente, calculando $\\Delta l$ para variaciones $\\Delta a$, $\\Delta b$, $\\Delta c$ muy peque침as.\n",
        "\n",
        "Para ellos haremos una funci칩n que nos calcule $l$ dado $a$, $b$ y $c$"
      ],
      "metadata": {
        "id": "-9gc_JnSeVxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_l(a,b,c):\n",
        "    m = a+b\n",
        "    n = torch.max(a,b)\n",
        "    p = m*n\n",
        "    l = p**2\n",
        "    return l"
      ],
      "metadata": {
        "id": "w5AczIuKej94"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chequeamos que el resultado es efectivamente **36**\n"
      ],
      "metadata": {
        "id": "OqiOM4eSeq-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ov = calculate_l(a, b, c)\n",
        "ov"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--U3tIQFeqlT",
        "outputId": "befac02c-0952-4b8f-db1d-047e0d90ce61"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([36.], grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego calcularemos $l$ introduciendo un peque침o cambio en $a$. Observaremos como resulta el ratio de cambio $\\Large \\frac{\\Delta l}{\\Delta a}$"
      ],
      "metadata": {
        "id": "cYvMsWcfewXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_change = 0.001\n",
        "nv = calculate_l(a + small_change, b, c)\n",
        "print(f'New value: {(nv).item()}')\n",
        "print(f'Change value: {(nv - ov).item()}')\n",
        "print(f'Change ration: {((nv - ov) / small_change).item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daLoA4KUe0Vx",
        "outputId": "3e627af7-2250-429b-e3d9-7595022332ee"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New value: 36.02400207519531\n",
            "Change value: 0.0240020751953125\n",
            "Change ration: 24.002073287963867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Efectivamente el ratio de variaci칩n es 24, como la derivada $\\Large \\frac{\\partial l}{\\partial a}$.\n",
        "Haremos lo mismo para $b$ y para $c$:"
      ],
      "metadata": {
        "id": "9M1__4HOe7dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nv = calculate_l(a , b + small_change, c)\n",
        "nv, (nv - ov) / small_change\n",
        "print(f'New value: {(nv).item()}')\n",
        "print(f'Change value: {(nv - ov).item()}')\n",
        "print(f'Change ration: {((nv - ov) / small_change).item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg2U1zuVe7OG",
        "outputId": "ae85fea6-835b-4fc9-fe75-3f1fffdf04ce"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New value: 36.06003189086914\n",
            "Change value: 0.060031890869140625\n",
            "Change ration: 60.03188705444336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nv = calculate_l(a , b, c + small_change)\n",
        "nv, (nv - ov) / small_change\n",
        "print(f'New value: {(nv).item()}')\n",
        "print(f'Change value: {(nv - ov).item()}')\n",
        "print(f'Change ration: {((nv - ov) / small_change).item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PybgnYitfFRt",
        "outputId": "2c372692-a068-432b-a881-a76064982689"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New value: 36.0\n",
            "Change value: 0.0\n",
            "Change ration: 0.0\n"
          ]
        }
      ]
    }
  ]
}