{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOaxLsvi8y0Ee3hxn0AewkN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gforconi/UTNIA2025/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "tW9D-RFVUJMi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduccion a Pytorch\n",
        "\n",
        "Pytorch es una libreria que permite trabajar con vectores y matrices de muchas dimensiones.\n",
        "\n",
        "En ese sentido es muy parecido a Numpy. En numpy a los vectores son llamados arrays. En pytorch se los llama tensores."
      ],
      "metadata": {
        "id": "aym_yfMPUE70"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1bPHectQTVUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1635cc6-5f03-41f3-8a84-ccbed078bba2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3.,  6.],\n",
              "        [ 9., 12.],\n",
              "        [ 1.,  2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "a = torch.tensor([[3.,6.],[9.,12.], [1.,2.]])\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BoN4tYvUZS8",
        "outputId": "4d76612a-42d9-45f9-9016-0fa9a7f77f64"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El shape del tensor es una lista del tamano de cada dimension. Si trabajamos con matrices (como comumnmente se llama a los vectores 2D), cada \"fila\" tiene la misma longitud: no hay una fila mas corta que otra.\n",
        "\n",
        "Lo mismo vale para mas dimensiones. No podemos hacer:"
      ],
      "metadata": {
        "id": "LlF7_o5JUemX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([[1., 2.], [3., 4.]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "CmcWDnDxUd4Y",
        "outputId": "a74969c1-a18e-48cb-a96a-54c2ac4aa298"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "expected sequence of length 2 at dim 1 (got 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-50bc8b394db2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: expected sequence of length 2 at dim 1 (got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El `ValueError` se debe a que las longitudes de las filas `[1., 2.]` y `[3]` no coinciden."
      ],
      "metadata": {
        "id": "I-brPNgUkOnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensores con Pytorch\n",
        "\n",
        "Un tensor es un concepto matemático que generaliza escalares, vectores y matrices hacia dimensiones superiores. Para ilustrarlo, un tensor de orden 0 se reduce a un escalar, mientras que un tensor de orden 1 se convierte en un vector. Cuando llegamos a una matriz de dos dimensiones, estamos ante un tensor de orden 2, y así sucesivamente hasta llegar a n dimensiones. Los tensores tienen una amplia aplicación en distintos ámbitos, desde las matemáticas y la física hasta la informática y el aprendizaje automático.\n",
        "\n",
        "En el contexto del aprendizaje automático y el aprendizaje profundo, los tensores son la base de datos fundamental que representa las entradas, salidas y el estado interno de una red neuronal.\n",
        "\n",
        "PyTorch, en su esencia, es una biblioteca especializada en el procesamiento de tensores. Ofrece una amplia variedad de funciones altamente optimizadas para operar eficientemente con estos objetos, incluyendo operaciones cruciales como multiplicaciones de matrices y convoluciones. Además, PyTorch se integra sin problemas con aceleradores de hardware como las GPU, lo que puede impulsar de manera significativa los cálculos necesarios en el aprendizaje profundo. Esta capacidad de PyTorch para trabajar con tensores y aprovechar al máximo el hardware subyacente lo convierte en una herramienta fundamental en el campo del aprendizaje automático y la inteligencia artificial."
      ],
      "metadata": {
        "id": "PjNGojrXiPTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creación de tensores\n",
        "\n",
        "A continuación varios ejemplos de cómo crear tensores en con Pytorch.\n"
      ],
      "metadata": {
        "id": "upA5fP3kixzT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Escalares**"
      ],
      "metadata": {
        "id": "oySL--O1i1Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escalares en PyTorch (tensor de orden 0)\n",
        "t1 = torch.tensor(4.)\n",
        "print(t1)\n",
        "print(\"Orden del tensor:\", t1.dim())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvR4lzlJiWOP",
        "outputId": "15b468a0-eb1a-4444-9eff-de3c51ce1c04"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n",
            "Orden del tensor: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`4.` es una abreviatura de `4.0.` Se emplea para indicar a Python (y PyTorch) que se desea crear un número en formato de coma flotante (`float`). Esto se puede verificar al revisar el atributo `dtype` de nuestro tensor."
      ],
      "metadata": {
        "id": "E7kW_enPi-n2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tipo de dato de un tensor\n",
        "t1.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEN0nKHNjIIT",
        "outputId": "a9be5f99-8f7e-4c3b-a416-7a26fdbaca4c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Vectores**"
      ],
      "metadata": {
        "id": "bO0YykB3jLXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector de 1 dimensión (tensor de orden 1)\n",
        "t2 = torch.tensor([1, 2, 3, 4])\n",
        "print(t2)\n",
        "print(f\"Orden del tensor: {t2.ndim}\")\n",
        "print(f\"Forma del tensor: {t2.shape}\")\n",
        "print(f\"Tipo de dato del tensor: {t2.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfs0T-WDjLMP",
        "outputId": "12e76b0b-d277-43bd-8356-ce60cdd60805"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4])\n",
            "Orden del tensor: 1\n",
            "Forma del tensor: torch.Size([4])\n",
            "Tipo de dato del tensor: torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todos los elementos de un tensor tienen el mismo tipo. Por esta razón, al crear un tensor que combina valores `float` y valores `int`, el tensor resultante adquiere el tipo `float`."
      ],
      "metadata": {
        "id": "K6dtecFljRra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2_mix = torch.tensor([1.0, 2, 3, 4])\n",
        "print(t2_mix)\n",
        "print(f\"Orden del tensor: {t2_mix.ndim}\")\n",
        "print(f\"Forma del tensor: {t2_mix.shape}\")\n",
        "print(f\"Tipo de dato del tensor: {t2_mix.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k30DCRCqjXTE",
        "outputId": "190c17a5-6614-4175-b76f-819a218a31fc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4.])\n",
            "Orden del tensor: 1\n",
            "Forma del tensor: torch.Size([4])\n",
            "Tipo de dato del tensor: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Matrices**"
      ],
      "metadata": {
        "id": "YhXrl-8cjaND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrices\n",
        "t3 = torch.tensor([[5., 6],\n",
        "                   [7, 8],\n",
        "                   [9, 10]])\n",
        "print(t3)\n",
        "print(f\"Orden del tensor: {t3.ndim}\")\n",
        "print(f\"Forma del tensor: {t3.shape}\")\n",
        "print(f\"Tipo de dato del tensor: {t3.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZIu_s6hjzgR",
        "outputId": "dc054e7b-bde6-4c57-d431-a0021dfb16c5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5.,  6.],\n",
            "        [ 7.,  8.],\n",
            "        [ 9., 10.]])\n",
            "Orden del tensor: 2\n",
            "Forma del tensor: torch.Size([3, 2])\n",
            "Tipo de dato del tensor: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tensor de 3 dimensiones**\n",
        "\n"
      ],
      "metadata": {
        "id": "mS3vWxL1j39c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor tridimensional\n",
        "t4 = torch.tensor([\n",
        "    [[11, 12, 13, 10],\n",
        "     [11, 12, 13, 10],\n",
        "     [13, 14, 15, 10]],\n",
        "    [[15, 16, 17, 10],\n",
        "     [11, 12, 13, 10],\n",
        "     [17, 18, 19., 10]]])"
      ],
      "metadata": {
        "id": "u4kg37Uyj6Qh"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tensor de orden  𝑛**\n",
        "\n",
        "Los tensores pueden tener cualquier número de dimensiones y diferentes longitudes a lo largo de cada dimensión. Se puede inspeccionar la longitud a lo largo de cada dimensión usando el atributo `.shape`. Al igual que pasa con NumPy, no es posible crear tensores con una dimensionalidad incompatible."
      ],
      "metadata": {
        "id": "eX0kIBxskAdI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generación de Tensores Aleatorios\n",
        "\n",
        "En el contexto de los modelos de aprendizaje automático, como las redes neuronales, se manipulan y buscan patrones dentro de los tensores. Por lo general, un modelo de aprendizaje automático comienza con tensores de números aleatorios (pesos y bias) que posteriormente se ajustan a medida que procesa los datos de entrenamiento y aprende de ellos.\n",
        "\n",
        "Para crear tensores con números aleatorios entre [0,1] se utiliza la funicón `torch.rand()` pasando el parámetro `size`."
      ],
      "metadata": {
        "id": "bX_rMDZ4knkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor con valores aleatorios de dimensiones (3, 4)\n",
        "tensor_aleatorio = torch.rand(size=(3, 4))\n",
        "print(tensor_aleatorio)\n",
        "print(f\"Orden del tensor: {tensor_aleatorio.ndim}\")\n",
        "print(f\"Forma del tensor: {tensor_aleatorio.shape}\")\n",
        "print(f\"Tipo de dato del tensor: {tensor_aleatorio.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOHPuzsdkl1g",
        "outputId": "7fcb68c2-2f40-40c4-baba-42bc0cbb9ff0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6546, 0.8298, 0.5365, 0.5581],\n",
            "        [0.6686, 0.4676, 0.7414, 0.3003],\n",
            "        [0.2640, 0.9841, 0.5748, 0.3204]])\n",
            "Orden del tensor: 2\n",
            "Forma del tensor: torch.Size([3, 4])\n",
            "Tipo de dato del tensor: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Operaciones con tensores\n",
        "\n",
        "Para poder crear, entrenar y luego realizar predicciones con una red neuronal, es esencial llevar a cabo operaciones fundamentales entre tensores, que incluyen:\n",
        "\n",
        "*   Suma\n",
        "*   Resta\n",
        "*   Multiplicación (elemento a elemento)\n",
        "*   División\n",
        "*   Multiplicación de matrices"
      ],
      "metadata": {
        "id": "DqNJ-jCbk-fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Suma\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZdR3x8elIoJ",
        "outputId": "f7c697f1-a631-4821-9a29-ec9712ce4d62"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resta\n",
        "tensor = tensor - 10\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbFGY51mlOyj",
        "outputId": "1c47681a-8708-4e05-8a23-cb400c25ffb4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplicación por un escalar\n",
        "tensor * 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RydqtQ_4lLTT",
        "outputId": "06c1c068-fe14-40b9-f037-2b24f60e23b0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-90, -80, -70])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiplicación de matrices\n",
        "\n",
        "\n",
        "La [multiplicación de matrices](https://www.mathsisfun.com/algebra/matrix-multiplying.html) es una de las operaciones más comunes en algoritmos de aprendizaje automático y aprendizaje profundo, como las redes neuronales. En PyTorch, esta funcionalidad se implementa a través del método torch.matmul(). Hay dos reglas principales a tener en cuenta al multiplicar matrices:\n",
        "\n",
        "\n",
        "\n",
        "1.   Las **dimensiones internas** deben coincidir:\n",
        "\n",
        "\n",
        "\n",
        "*   `(3, 2) @ (3, 2)` no es válido\n",
        "*   `(2, 3) @ (3, 2)` es válido\n",
        "*   `(3, 2) @ (2, 3)` es válido\n",
        "\n",
        "\n",
        "2.   La matriz resultante tiene la forma de las **dimensiones externas**:\n",
        "*   `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
        "*   `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
        "\n"
      ],
      "metadata": {
        "id": "V5WY0Nn3lX8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es importante diferenciar entre la multiplicación elemento a elemento (element wise) y la multiplicación de matrices. Por ejemplo, para un `tensor` con valores `[1, 2, 3]`:\n",
        "\n",
        "| **Operación**                       | **Cálculo**                                | **Código**                |\n",
        "|------------------------------------|--------------------------------------------|---------------------------|\n",
        "| Multiplicación elemento a elemento | `[1*1, 2*2, 3*3] = [1, 4, 9]`               | `tensor * tensor`         |\n",
        "| Multiplicación de matrices         | `[1*1 + 2*2 + 3*3] = [14]`                  | `tensor.matmul(tensor)`   |\n"
      ],
      "metadata": {
        "id": "a0_zydYwmb-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3])"
      ],
      "metadata": {
        "id": "pbNQRj70m9l9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplicación elemento a elemento de tensores\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor * tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmjA2pBom-Ui",
        "outputId": "bcf4d452-d1e5-4e51-bf42-c0f833e27b9c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplicación matricial con el operador @\n",
        "tensor @ tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4ltH3EmnCP8",
        "outputId": "5cdba2f5-2516-40a8-c47f-5ee90c7c6383"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplicación matricial con el método matmul\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bGVQYEnnLgK",
        "outputId": "20912dda-0109-4b50-9b49-3925c334dde0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cálculo del valor máximo, mínimo, média y suma de un tensor"
      ],
      "metadata": {
        "id": "NRcBt0nSnRaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cálculo del valor máximo, mínimo, média y suma de un tensor\n",
        "x = torch.tensor([1,2,1,3,1,2], dtype=torch.float32)  # para calcular la media hay que convertir a float\n",
        "print(f\"Min: {x.min()}\")\n",
        "print(f\"Max: {x.max()}\")\n",
        "print(f\"Media: {x.mean()}\")\n",
        "print(f\"Suma: {x.sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-yZV6QAnTo2",
        "outputId": "2e33244a-d225-484d-d239-d20a63389111"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min: 1.0\n",
            "Max: 3.0\n",
            "Media: 1.6666666269302368\n",
            "Suma: 10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Índices de los Valores Máximo y Mínimo\n",
        "\n",
        "Es posible determinar el índice de un tensor donde se encuentra el valor máximo o mínimo utilizando las funciones `torch.argmax()` y `torch.argmin()`. Esta operación resulta útil en situaciones en las que sólo se requiere conocer la posición del valor más alto (o más bajo), y no el valor en sí. Veremos un ejemplo de esto más adelante cuando utilicemos la función de activación softmax."
      ],
      "metadata": {
        "id": "EWK2R-EVnYH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtención del índice del valor máximo y mínimo de un tensor\n",
        "tensor = torch.arange(10, 100, 10)\n",
        "print(f\"Tensor: {tensor}\")\n",
        "\n",
        "# Se devuelve el índice del valor máximo y mínimo\n",
        "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
        "print(f\"Index where min value occurs: {tensor.argmin()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoS-lN6OniAk",
        "outputId": "bed0a75f-ab49-47f8-c0ab-fe582b7fc2c7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "Index where max value occurs: 8\n",
            "Index where min value occurs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Que introduce de nuevo pytorch sobre numpy\n",
        "Esencialmente dos cosas:\n",
        "\n",
        "*   Paralelizacion en GPU\n",
        "*   Calculo automatico de derivadas (gradiente)\n",
        "\n",
        "\n",
        "Estas funciones son muy deseables cuando trabajamos con redes neuronales. Aunque tambien hay librerias de, por ejemplo, algebra lineal que han aprovechado esto para ser escritas sobre pytorch y funcionar eficientemente.\n",
        "\n",
        "Pytorch tambien provee muchas de las funcionalidades necesarias para definir una red y entrenarla.\n",
        "\n",
        "Con la siguiente funcion podemos ver si tenemos una GPU disponible en nuestro sistema"
      ],
      "metadata": {
        "id": "-jtWib7iUs2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEgDIhzrU7Ec",
        "outputId": "4cc8b59f-fded-49b2-8849-60f0bcd2b228"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos comparar la velocidad entre ejecutar algo en CPU o usando GPU (si tenemos).\n",
        "\n",
        "Pytorch requiere mover explicitamente los tensores a la GPU, se puede hacer facilmente mediante el metodo .cuda()\n",
        "\n",
        "(Si se operan vectores que estan en la GPU con vectores que estan en la GPU causara un error)"
      ],
      "metadata": {
        "id": "J3R1PzDRU-_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.rand(1000,1000)\n",
        "B = torch.rand(1000,1000)"
      ],
      "metadata": {
        "id": "t5pLuG51VDc1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit A@B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znmJKPf3VFQo",
        "outputId": "f4a8a2a5-67bc-4f0d-ba0b-2152d85a65ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32.8 ms ± 3.05 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.rand(1000,1000)\n",
        "B = torch.rand(1000,1000)\n",
        "if torch.cuda.is_available():\n",
        "    A = A.cuda()\n",
        "    B = B.cuda()\n",
        "    print(\"CUDA available\")\n",
        "else:\n",
        "    print(\"CUDA not available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8t6P_C9VJRD",
        "outputId": "45aed761-5de3-495d-acd8-85095bac336b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit A@B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTKSs_xmVcv6",
        "outputId": "3825c436-9fe6-4a38-877d-72920e35c3f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "556 µs ± 17.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si tenés iOS (Mac) podés ver como acelerar Pytorch con el backedn MPS (solo disponible para AMD o Sillicon Chip, NO Intel)."
      ],
      "metadata": {
        "id": "J2kVhf7RVk13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.backends.mps.is_available():\n",
        "    mps_device = torch.device(\"mps\")\n",
        "    print(\"MPS available\")\n",
        "    A = A.to(mps_device)\n",
        "    B = B.to(mps_device)\n",
        "else:\n",
        "    print (\"MPS device not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AmS8iM-VkM8",
        "outputId": "c76de7f4-3ec8-4752-dcde-b2b1e24ae0ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MPS device not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit A@B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuJ1oyDvVsqd",
        "outputId": "0045e3e2-ec99-4bf5-95dc-8d4f9fa66ffe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "575 µs ± 15.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd\n",
        "\n",
        "Autograd es una biblioteca de PyTorch que implementa la diferenciación automática. Utiliza la estructura gráfica para calcular gradientes y permite que el modelo aprenda actualizando sus parámetros durante el entrenamiento. Autograd también permite calcular gradientes con respecto a valores escalares arbitrarios, lo cual resulta útil para tareas como la optimización.\n",
        "\n",
        "Es necesaria la instalacion de complementos en el sistema operativo y de la libreria `torchviz`"
      ],
      "metadata": {
        "id": "yCufW9M0cXrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y graphviz\n",
        "!pip install torchviz"
      ],
      "metadata": {
        "id": "fD_vlsVLXXzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchviz import make_dot\n",
        "\n",
        "# Creamos un tensor y asignamos el valor 7\n",
        "# seteamos requires_grad=True\n",
        "# Entonces, autograd registrará las operaciones\n",
        "x=torch.tensor(7.0,requires_grad=True)\n",
        "\n",
        "# Definimos la funcion\n",
        "f = (x**2)+3\n",
        "\n",
        "# Diferencial usando torch\n",
        "# Utiliza la funcion inversa para calcualr el valor del gradiente\n",
        "f.backward()\n",
        "\n",
        "# Imprimimos el valor de la derivada de \"y\"\n",
        "# es decir, dy/dx = 2x  = 2 X 7.0 = 14.\n",
        "print(x.grad)\n",
        "\n",
        "# Imprimimos el grafo computacional\n",
        "make_dot(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "1yrWTSyVYXgC",
        "outputId": "afa8ef6e-add6-48ff-862d-954636ba5b32"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(14.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"109pt\" height=\"271pt\"\n viewBox=\"0.00 0.00 109.00 271.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 267)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-267 105,-267 105,4 -4,4\"/>\n<!-- 137462710737360 -->\n<g id=\"node1\" class=\"node\">\n<title>137462710737360</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 137463050253936 -->\n<g id=\"node2\" class=\"node\">\n<title>137463050253936</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-86 6,-86 6,-67 95,-67 95,-86\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 137463050253936&#45;&gt;137462710737360 -->\n<g id=\"edge4\" class=\"edge\">\n<title>137463050253936&#45;&gt;137462710737360</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n</g>\n<!-- 137463050244864 -->\n<g id=\"node3\" class=\"node\">\n<title>137463050244864</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 137463050244864&#45;&gt;137463050253936 -->\n<g id=\"edge1\" class=\"edge\">\n<title>137463050244864&#45;&gt;137463050253936</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.75C50.5,-114.8 50.5,-104.85 50.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-96.09 50.5,-86.09 47,-96.09 54,-96.09\"/>\n</g>\n<!-- 137463050254320 -->\n<g id=\"node4\" class=\"node\">\n<title>137463050254320</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-196 0,-196 0,-177 101,-177 101,-196\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 137463050254320&#45;&gt;137463050244864 -->\n<g id=\"edge2\" class=\"edge\">\n<title>137463050254320&#45;&gt;137463050244864</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.75C50.5,-169.8 50.5,-159.85 50.5,-151.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.09 50.5,-141.09 47,-151.09 54,-151.09\"/>\n</g>\n<!-- 137463078805264 -->\n<g id=\"node5\" class=\"node\">\n<title>137463078805264</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-263 23.5,-263 23.5,-232 77.5,-232 77.5,-263\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 137463078805264&#45;&gt;137463050254320 -->\n<g id=\"edge3\" class=\"edge\">\n<title>137463078805264&#45;&gt;137463050254320</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.92C50.5,-224.22 50.5,-214.69 50.5,-206.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-206.25 50.5,-196.25 47,-206.25 54,-206.25\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7d05a4589810>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd a otro nivel\n",
        "\n",
        "Podemos definir vectores con ciertos valores y crear otros como resultado de operar los primeros y pytorch recordara el grafo de las computaciones.\n",
        "\n",
        "Supongamos que tenemos los valores:\n",
        "\n",
        "$ a = 1 $\n",
        "\n",
        "$ b = 2 $\n",
        "\n",
        "$ c = 0 $\n",
        "\n",
        "Y definimos $m$, $n$ (capas intermedias), $p$ (una prediccion) y $l$ (un costo) como:\n",
        "\n",
        "$ m = a + b $\n",
        "\n",
        "$ n = max(b,c) $\n",
        "\n",
        "$ p = m \\times n $\n",
        "\n",
        "$ l = p^2 $\n",
        "\n",
        "Pytorch calculara los valores intermedios dado el valor de las hojas:\n",
        "\n",
        "$ m = 3 $\n",
        "\n",
        "$ n = 2 $\n",
        "\n",
        "$ p = 6 $\n",
        "\n",
        "$ l = 36 $\n",
        "\n",
        "Y a la vez construira el siguiente grafo de computaciones (https://csacademy.com/app/graph_editor/)\n",
        "\n",
        "![Grafo](graph.png)\n",
        "\n",
        "Si $a$,$b$,$c$ son nuestros parametros y queremos minimizar el costo $l$. Querremos calcular: $\\Large\\frac{\\partial l}{\\partial a}$, $\\Large\\frac{\\partial l}{\\partial b}$, $\\Large\\frac{\\partial l}{\\partial c}$\n",
        "\n",
        "A primera vista no es fácil calcular dichas derivadas. En general, usando la definición de los valores, podemos calcular la derivada de un valor en función de los valores que dependen de forma directa de él. Haciendo referencia al grafo de las computaciones (la imagen de arriba), podemos calcular el valor de $\\large\\frac{\\partial y}{\\partial x}$ si existe una arista que $x \\rightarrow y$. Así, podemos calcular las siguientes derivadas, ya que cada variable depende de forma directa una de la otra:\n",
        "\n",
        "$\\large\\frac{\\partial l}{\\partial p} = 2 \\times p = 12$\n",
        "\n",
        "$\\large\\frac{\\partial p}{\\partial m} = n = 2$\n",
        "\n",
        "$\\large\\frac{\\partial p}{\\partial n} = m = 3$\n",
        "\n",
        "$\\large\\frac{\\partial m}{\\partial a} = 1$\n",
        "\n",
        "$\\large \\frac{\\partial m}{\\partial b} = 1$\n",
        "\n",
        "$\\large \\frac{\\partial n}{\\partial b} = 1$\n",
        "\n",
        "$\\large \\frac{\\partial n}{\\partial c} = 0$\n",
        "\n",
        "Pero como hacemos para calcular las derivadas $\\Large\\frac{\\partial l}{\\partial a}$, $\\Large\\frac{\\partial l}{\\partial b}$, $\\Large\\frac{\\partial l}{\\partial c}$ que son las que necesitamos para actualizar el gradiente?\n",
        "\n",
        "Centrémosnos por un momento en el caso de $\\Large\\frac{\\partial l}{\\partial a}$. Si bien no tenemos una fórmula que relacione de manera directa $a$ con $l$, el valor de $l$ depende del valor de $a$: esto es debido a que el valor de $l$ depende de $p$, que a su vez depende de $m$, que por último depende de $a$.\n",
        "\n",
        "Apliquemos la [regla de la cadena](https://en.wikipedia.org/wiki/Chain_rule) entre $p$ (que es una función de $a$), $l$ (que es función de $p$) y $a$:\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial a} = \\frac{\\partial l}{\\partial p} \\times \\frac{\\partial p}{\\partial a}$\n",
        "\n",
        "Mirando el término de la derecha:\n",
        "- $\\Large \\frac{\\partial l}{\\partial p}$ lo conocemos y vale $12$.\n",
        "- $\\Large \\frac{\\partial p}{\\partial a}$ no lo hemos calculado aún, pero nos hemos \"acercado\" a $a$ en el grafo de las computaciones. Todo indica que si aplicamos una vez más la regla de la cadena terminaremos llegando a $a$. Apliquemos pues, la regla de la cadena sobre $m$, $p$ y $a$:\n",
        "\n",
        "$\\Large\\frac{\\partial p}{\\partial a} = \\frac{\\partial p}{\\partial m} \\times \\frac{\\partial m}{\\partial a}$\n",
        "\n",
        "Ahora, mirando el término de la derecha, tenemos todos los valores: $\\Large \\frac{\\partial p}{\\partial m}$ vale 2 y $\\Large \\frac{\\partial m}{\\partial a}$ vale 1.\n",
        "\n",
        "Ya estamos en condiciones pues de calcular $\\Large\\frac{\\partial l}{\\partial a}$:\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial a} = \\frac{\\partial l}{\\partial p} \\times \\frac{\\partial p}{\\partial a} = 12 \\times \\frac{\\partial p}{\\partial m} \\times \\frac{\\partial m}{\\partial a} = 12 \\times 2 \\times 1 = 24$\n",
        "\n",
        "Ordenando nuestro razonamiento, lo que estamos haciendo es calcular los gradientes respecto de las variables que están más cerca del resultado:\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial m} = \\frac{\\partial l}{\\partial p} \\times \\frac{\\partial p}{\\partial m} = 12 \\times 2 = 24$\n",
        "\n",
        "\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial n} = \\frac{\\partial l}{\\partial p} \\times \\frac{\\partial p}{\\partial n} = 12 \\times 3 = 36$\n",
        "\n",
        "Y luego utilizar dichos gradientes para calcular los de las capas anteriores:\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial a} = \\frac{\\partial l}{\\partial m} \\times \\frac{\\partial m}{\\partial a} = 24 \\times 1 = 24$\n",
        "\n",
        "\n",
        "Podemos hacer lo mismo para calcular $\\Large\\frac{\\partial l}{\\partial c}$.\n",
        "\n",
        "\n",
        "Para el caso de $b$ usamos la [regla de la cadena multivariada](https://math.hmc.edu/calculus/hmc-mathematics-calculus-online-tutorials/multivariable-calculus/multi-variable-chain-rule/) (es muy parecida a la regla del producto, de hecho la regla del producto es un caso particular de la regla de la cadena multivariada). Esta aplica porque $b$ es usada en varios valores ($m$ y $n$) de los cuales depende en última instancia el valor que queremos diferenciar $l$.\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial b} = \\frac{\\partial l}{\\partial m} \\times \\frac{\\partial m}{\\partial b} + \\frac{\\partial l}{\\partial n} \\times \\frac{\\partial n}{\\partial b} = 24+36 = 60$\n"
      ],
      "metadata": {
        "id": "k-OJkc4Hc1xU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a calcular los gradientes usando [Pytorch Autograd](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html) (diferenciación automática).\n",
        "\n",
        "Primero definimos los valores hoja (de los que depende el resto). Serían nuestro parámetros (respecto de los cuales vamos a derivar después). Es importante el argumento requires_grad para que Pytorch sepa que tiene que calcular el grafo de las computaciones que le apliquemos a dichas variables, porque vamos a querer el gradiente respecto a dichas variables:"
      ],
      "metadata": {
        "id": "i0wfTsC6dsyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1.],requires_grad=True)\n",
        "b = torch.tensor([2.],requires_grad=True)\n",
        "c = torch.tensor([0.],requires_grad=True)\n",
        "a,b,c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mczHZe7Ldv4o",
        "outputId": "96f53f22-870b-4521-e3de-0a6f47790aaa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.], requires_grad=True),\n",
              " tensor([2.], requires_grad=True),\n",
              " tensor([0.], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora podemos definir otros valores en relación a los anteriores. En grad_fn lo que vemos es que Pytorch está llevando un historial de como dichos valores fueron contruídos. Esto es el grafo de las computaciones que luego le servirá para calcular el gradiente:"
      ],
      "metadata": {
        "id": "YiHGlJNad58k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = a+b\n",
        "n = torch.max(a,b)\n",
        "m, n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dl1lCdKd7vi",
        "outputId": "45c927a5-e650-41e8-b586-a49e9cbbe52c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([3.], grad_fn=<AddBackward0>),\n",
              " tensor([2.], grad_fn=<MaximumBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = m*n\n",
        "l = p**2\n",
        "p, l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VxG8GBwd9kE",
        "outputId": "3d8e93e8-045b-4269-f70c-c27ba91ef69f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([6.], grad_fn=<MulBackward0>), tensor([36.], grad_fn=<PowBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para calcular el gradiente de $l$ basta con llamar l.backwards()\n",
        "\n",
        "Generalmente sólo usamos los gradientes respecto a los parámetros (las hojas). Si bien Pytorch calcula los gradientes respecto a los nodos intermedios (es un resultado parcial que luego ayudará para calcular los gradientes en las hojas), los borra automáticamente luego de usarlos para ahorrar memoria. Esto se puede evitar con el método .retain_grad(). En este caso le pediremos a Pytorch que no los borre ya que los queremos mostrar para corroborar que nos dio el mismo resultado que el que hallamos de manera analítica:"
      ],
      "metadata": {
        "id": "weK2QLGeeDf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m.retain_grad()\n",
        "n.retain_grad()\n",
        "p.retain_grad()\n",
        "l.retain_grad()\n",
        "\n",
        "l.backward()"
      ],
      "metadata": {
        "id": "2i1m0N0deHEX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último mostramos los gradientes de $l$ respecto a cada una de las variables. Podemos corroborar que los valores son los mismo que los hallados de manera analítica arriba:"
      ],
      "metadata": {
        "id": "jLunGkFfeLYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l.grad, p.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToB28OfAeKzx",
        "outputId": "f54d6a9b-0631-4bf7-ff94-e93157e4210f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.]), tensor([12.]))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.grad, n.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoNqf-E9eQTS",
        "outputId": "55ea56ab-f2e0-43ff-8d31-8d32d694a4e6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([24.]), tensor([36.]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad, b.grad, c.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJX8vUryeSpG",
        "outputId": "1e81b83c-ab24-4ca8-f535-86c3af8baf4c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([24.]), tensor([60.]), None)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretación del gradiente\n",
        "\n",
        "Recordar que el gradiente $\\Large \\frac{\\partial l}{\\partial a}$ indica cuánto cambia $l$ ante pequeños cambios de $a$:\n",
        "\n",
        "$\\Large \\frac{\\partial l}{\\partial a} = lim_{\\Delta a \\rightarrow 0} \\frac{\\Delta l}{\\Delta a}$\n",
        "\n",
        "Corroboraremos esto empíricamente, calculando $\\Delta l$ para variaciones $\\Delta a$, $\\Delta b$, $\\Delta c$ muy pequeñas.\n",
        "\n",
        "Para ellos haremos una función que nos calcule $l$ dado $a$, $b$ y $c$"
      ],
      "metadata": {
        "id": "-9gc_JnSeVxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_l(a,b,c):\n",
        "    m = a+b\n",
        "    n = torch.max(a,b)\n",
        "    p = m*n\n",
        "    l = p**2\n",
        "    return l"
      ],
      "metadata": {
        "id": "w5AczIuKej94"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chequeamos que el resultado es efectivamente **36**\n"
      ],
      "metadata": {
        "id": "OqiOM4eSeq-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ov = calculate_l(a, b, c)\n",
        "ov"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--U3tIQFeqlT",
        "outputId": "befac02c-0952-4b8f-db1d-047e0d90ce61"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([36.], grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego calcularemos $l$ introduciendo un pequeño cambio en $a$. Observaremos como resulta el ratio de cambio $\\Large \\frac{\\Delta l}{\\Delta a}$"
      ],
      "metadata": {
        "id": "cYvMsWcfewXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_change = 0.001\n",
        "nv = calculate_l(a + small_change, b, c)\n",
        "print(f'New value: {(nv).item()}')\n",
        "print(f'Change value: {(nv - ov).item()}')\n",
        "print(f'Change ration: {((nv - ov) / small_change).item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daLoA4KUe0Vx",
        "outputId": "3e627af7-2250-429b-e3d9-7595022332ee"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New value: 36.02400207519531\n",
            "Change value: 0.0240020751953125\n",
            "Change ration: 24.002073287963867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Efectivamente el ratio de variación es 24, como la derivada $\\Large \\frac{\\partial l}{\\partial a}$.\n",
        "Haremos lo mismo para $b$ y para $c$:"
      ],
      "metadata": {
        "id": "9M1__4HOe7dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nv = calculate_l(a , b + small_change, c)\n",
        "nv, (nv - ov) / small_change\n",
        "print(f'New value: {(nv).item()}')\n",
        "print(f'Change value: {(nv - ov).item()}')\n",
        "print(f'Change ration: {((nv - ov) / small_change).item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg2U1zuVe7OG",
        "outputId": "ae85fea6-835b-4fc9-fe75-3f1fffdf04ce"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New value: 36.06003189086914\n",
            "Change value: 0.060031890869140625\n",
            "Change ration: 60.03188705444336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nv = calculate_l(a , b, c + small_change)\n",
        "nv, (nv - ov) / small_change\n",
        "print(f'New value: {(nv).item()}')\n",
        "print(f'Change value: {(nv - ov).item()}')\n",
        "print(f'Change ration: {((nv - ov) / small_change).item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PybgnYitfFRt",
        "outputId": "2c372692-a068-432b-a881-a76064982689"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New value: 36.0\n",
            "Change value: 0.0\n",
            "Change ration: 0.0\n"
          ]
        }
      ]
    }
  ]
}